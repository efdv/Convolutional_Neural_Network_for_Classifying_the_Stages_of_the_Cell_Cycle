{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tflib as lib\n",
    "import tflib.ops.linear\n",
    "import tflib.ops.conv2d\n",
    "import tflib.ops.batchnorm\n",
    "import tflib.ops.deconv2d\n",
    "import tflib.save_images\n",
    "import tflib.mnist\n",
    "import tflib.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'wgan-gp' # dcgan, wgan, or wgan-gp\n",
    "DIM = 64 # Model dimensionality\n",
    "BATCH_SIZE = 50 # Batch size\n",
    "CRITIC_ITERS = 5 # For WGAN and WGAN-GP, number of critic iters per gen iter\n",
    "LAMBDA = 10 # Gradient penalty lambda hyperparameter\n",
    "ITERS = 200000 # How many generator iterations to train for \n",
    "OUTPUT_DIM = 4096 # Number of pixels in MNIST (64*64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uppercase local vars:\n"
     ]
    }
   ],
   "source": [
    "lib.print_model_settings(locals().copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeakyReLU(x, alpha=0.2):\n",
    "    return tf.maximum(alpha*x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(\n",
    "        name+'.Linear', \n",
    "        n_in, \n",
    "        n_out, \n",
    "        inputs,\n",
    "        initialization='he'\n",
    "    )\n",
    "    return tf.nn.relu(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeakyReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(\n",
    "        name+'.Linear', \n",
    "        n_in, \n",
    "        n_out, \n",
    "        inputs,\n",
    "        initialization='he'\n",
    "    )\n",
    "    return LeakyReLU(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator(n_samples, noise=None):\n",
    "    if noise is None:\n",
    "        noise = tf.random.normal([n_samples, 128])\n",
    "\n",
    "    output = lib.ops.linear.Linear('Generator.Input', 128, 4*4*4*DIM, noise)\n",
    "    if MODE == 'wgan':\n",
    "        output = lib.ops.batchnorm.Batchnorm('Generator.BN1', [0], output)\n",
    "    output = tf.nn.relu(output)\n",
    "    output = tf.reshape(output, [-1, 4*DIM, 4, 4])\n",
    "\n",
    "    output = lib.ops.deconv2d.Deconv2D('Generator.2', 4*DIM, 2*DIM, 5, output)\n",
    "    if MODE == 'wgan':\n",
    "        output = lib.ops.batchnorm.Batchnorm('Generator.BN2', [0,2,3], output)\n",
    "    output = tf.nn.relu(output)\n",
    "\n",
    "    output = output[:,:,:7,:7]\n",
    "\n",
    "    output = lib.ops.deconv2d.Deconv2D('Generator.3', 2*DIM, DIM, 5, output)\n",
    "    if MODE == 'wgan':\n",
    "        output = lib.ops.batchnorm.Batchnorm('Generator.BN3', [0,2,3], output)\n",
    "    output = tf.nn.relu(output)\n",
    "\n",
    "    output = lib.ops.deconv2d.Deconv2D('Generator.5', DIM, 1, 5, output)\n",
    "    output = tf.nn.sigmoid(output)\n",
    "\n",
    "    return tf.reshape(output, [-1, OUTPUT_DIM])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(inputs):\n",
    "    output = tf.reshape(inputs, [-1, 1, 64, 64])\n",
    "\n",
    "    output = lib.ops.conv2d.Conv2D('Discriminator.1',1,DIM,5,output,stride=2)\n",
    "    output = LeakyReLU(output)\n",
    "\n",
    "    output = lib.ops.conv2d.Conv2D('Discriminator.2', DIM, 2*DIM, 5, output, stride=2)\n",
    "    if MODE == 'wgan':\n",
    "        output = lib.ops.batchnorm.Batchnorm('Discriminator.BN2', [0,2,3], output)\n",
    "    output = LeakyReLU(output)\n",
    "\n",
    "    output = lib.ops.conv2d.Conv2D('Discriminator.3', 2*DIM, 4*DIM, 5, output, stride=2)\n",
    "    if MODE == 'wgan':\n",
    "        output = lib.ops.batchnorm.Batchnorm('Discriminator.BN3', [0,2,3], output)\n",
    "    output = LeakyReLU(output)\n",
    "\n",
    "    output = tf.reshape(output, [-1, 4*4*4*DIM])\n",
    "    output = lib.ops.linear.Linear('Discriminator.Output', 4*4*4*DIM, 1, output)\n",
    "\n",
    "    return tf.reshape(output, [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Variable is unhashable. Instead, use variable.ref() as the key. (Variable: <tf.Variable 'Generator.Input/Generator.Input.W:0' shape=(128, 4096) dtype=float32, numpy=\narray([[ 0.02567775, -0.02669399, -0.01812933, ..., -0.03175392,\n        -0.02235023, -0.01022566],\n       [-0.01484493,  0.00863906, -0.01036157, ...,  0.00751138,\n        -0.01818066, -0.03466291],\n       [ 0.00817575,  0.0166621 ,  0.03102938, ...,  0.00167163,\n        -0.02021211, -0.02805721],\n       ...,\n       [ 0.03072485, -0.01196431,  0.00519867, ..., -0.00522642,\n         0.02819545, -0.00683101],\n       [-0.01217334, -0.02364941, -0.00086858, ...,  0.02179544,\n        -0.00736717, -0.00091929],\n       [ 0.02785378, -0.02328118,  0.02192808, ..., -0.02472678,\n         0.02378554,  0.00449341]], dtype=float32)>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\OneDrive - Universidad de Guanajuato\\EF-Duque-Vazquez-Doctorado\\projects\\cell_cycle\\code\\WGAN.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/OneDrive%20-%20Universidad%20de%20Guanajuato/EF-Duque-Vazquez-Doctorado/projects/cell_cycle/code/WGAN.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m real_data \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mVariable(initial_value\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mzeros(shape\u001b[39m=\u001b[39m(BATCH_SIZE, OUTPUT_DIM), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32), trainable\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/OneDrive%20-%20Universidad%20de%20Guanajuato/EF-Duque-Vazquez-Doctorado/projects/cell_cycle/code/WGAN.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#real_data = tf.placeholder(tf.float32, shape=[BATCH_SIZE, OUTPUT_DIM])\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/OneDrive%20-%20Universidad%20de%20Guanajuato/EF-Duque-Vazquez-Doctorado/projects/cell_cycle/code/WGAN.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m fake_data \u001b[39m=\u001b[39m Generator(BATCH_SIZE)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/OneDrive%20-%20Universidad%20de%20Guanajuato/EF-Duque-Vazquez-Doctorado/projects/cell_cycle/code/WGAN.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m disc_real \u001b[39m=\u001b[39m Discriminator(real_data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/OneDrive%20-%20Universidad%20de%20Guanajuato/EF-Duque-Vazquez-Doctorado/projects/cell_cycle/code/WGAN.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m disc_fake \u001b[39m=\u001b[39m Discriminator(fake_data)\n",
      "\u001b[1;32me:\\OneDrive - Universidad de Guanajuato\\EF-Duque-Vazquez-Doctorado\\projects\\cell_cycle\\code\\WGAN.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/OneDrive%20-%20Universidad%20de%20Guanajuato/EF-Duque-Vazquez-Doctorado/projects/cell_cycle/code/WGAN.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m noise \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/OneDrive%20-%20Universidad%20de%20Guanajuato/EF-Duque-Vazquez-Doctorado/projects/cell_cycle/code/WGAN.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     noise \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal([n_samples, \u001b[39m128\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/OneDrive%20-%20Universidad%20de%20Guanajuato/EF-Duque-Vazquez-Doctorado/projects/cell_cycle/code/WGAN.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m output \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mlinear\u001b[39m.\u001b[39;49mLinear(\u001b[39m'\u001b[39;49m\u001b[39mGenerator.Input\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m128\u001b[39;49m, \u001b[39m4\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m4\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m4\u001b[39;49m\u001b[39m*\u001b[39;49mDIM, noise)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/OneDrive%20-%20Universidad%20de%20Guanajuato/EF-Duque-Vazquez-Doctorado/projects/cell_cycle/code/WGAN.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mif\u001b[39;00m MODE \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mwgan\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/OneDrive%20-%20Universidad%20de%20Guanajuato/EF-Duque-Vazquez-Doctorado/projects/cell_cycle/code/WGAN.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     output \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mbatchnorm\u001b[39m.\u001b[39mBatchnorm(\u001b[39m'\u001b[39m\u001b[39mGenerator.BN1\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m0\u001b[39m], output)\n",
      "File \u001b[1;32me:\\OneDrive - Universidad de Guanajuato\\EF-Duque-Vazquez-Doctorado\\projects\\cell_cycle\\code\\tflib\\ops\\linear.py:108\u001b[0m, in \u001b[0;36mLinear\u001b[1;34m(name, input_dim, output_dim, inputs, biases, initialization, weightnorm, gain)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mInvalid initialization!\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    106\u001b[0m weight_values \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m gain\n\u001b[1;32m--> 108\u001b[0m weight \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mparam(\n\u001b[0;32m    109\u001b[0m     name \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m.W\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    110\u001b[0m     weight_values\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    113\u001b[0m \u001b[39mif\u001b[39;00m weightnorm\u001b[39m==\u001b[39m\u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     weightnorm \u001b[39m=\u001b[39m _default_weightnorm\n",
      "File \u001b[1;32me:\\OneDrive - Universidad de Guanajuato\\EF-Duque-Vazquez-Doctorado\\projects\\cell_cycle\\code\\tflib\\__init__.py:30\u001b[0m, in \u001b[0;36mparam\u001b[1;34m(name, *args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m result \u001b[39m=\u001b[39m _params[name]\n\u001b[0;32m     29\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 30\u001b[0m \u001b[39mwhile\u001b[39;00m result \u001b[39min\u001b[39;49;00m _param_aliases:\n\u001b[0;32m     31\u001b[0m     \u001b[39m# print 'following alias {}: {} to {}'.format(i, result, _param_aliases[result])\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     33\u001b[0m     result \u001b[39m=\u001b[39m _param_aliases[result]\n",
      "File \u001b[1;32me:\\python\\Lib\\site-packages\\tensorflow\\python\\ops\\variables.py:1018\u001b[0m, in \u001b[0;36mVariable.__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__hash__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1017\u001b[0m   \u001b[39mif\u001b[39;00m ops\u001b[39m.\u001b[39mTensor\u001b[39m.\u001b[39m_USE_EQUALITY \u001b[39mand\u001b[39;00m ops\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1018\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   1019\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mVariable is unhashable. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1020\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInstead, use variable.ref() as the key. (Variable: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1021\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Variable is unhashable. Instead, use variable.ref() as the key. (Variable: <tf.Variable 'Generator.Input/Generator.Input.W:0' shape=(128, 4096) dtype=float32, numpy=\narray([[ 0.02567775, -0.02669399, -0.01812933, ..., -0.03175392,\n        -0.02235023, -0.01022566],\n       [-0.01484493,  0.00863906, -0.01036157, ...,  0.00751138,\n        -0.01818066, -0.03466291],\n       [ 0.00817575,  0.0166621 ,  0.03102938, ...,  0.00167163,\n        -0.02021211, -0.02805721],\n       ...,\n       [ 0.03072485, -0.01196431,  0.00519867, ..., -0.00522642,\n         0.02819545, -0.00683101],\n       [-0.01217334, -0.02364941, -0.00086858, ...,  0.02179544,\n        -0.00736717, -0.00091929],\n       [ 0.02785378, -0.02328118,  0.02192808, ..., -0.02472678,\n         0.02378554,  0.00449341]], dtype=float32)>)"
     ]
    }
   ],
   "source": [
    "real_data = tf.Variable(initial_value=tf.zeros(shape=(BATCH_SIZE, OUTPUT_DIM), dtype=tf.float32), trainable=False)\n",
    "#real_data = tf.placeholder(tf.float32, shape=[BATCH_SIZE, OUTPUT_DIM])\n",
    "fake_data = Generator(BATCH_SIZE)\n",
    "\n",
    "disc_real = Discriminator(real_data)\n",
    "disc_fake = Discriminator(fake_data)\n",
    "\n",
    "gen_params = lib.params_with_name('Generator')\n",
    "disc_params = lib.params_with_name('Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
